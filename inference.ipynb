{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "import econml\n",
    "from econml.dml import DML, LinearDML, SparseLinearDML, CausalForestDML\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import tournament\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.linear_model import (Lasso, LassoCV, LogisticRegression,\n",
    "                                  LogisticRegressionCV, LinearRegression,\n",
    "                                  MultiTaskElasticNet, MultiTaskElasticNetCV)\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dowhy import CausalModel\n",
    "# import pgmpy\n",
    "# from pgmpy.base import DAG\n",
    "# from pgmpy.metrics import log_likelihood_score, correlation_score, structure_score\n",
    "# from pgmpy.estimators import BDeuScore, BDsScore, BicScore, K2Score\n",
    "\n",
    "import myUtils\n",
    "from myUtils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ate(parent, child, data_df, ref_df, dg, T0, T1):\n",
    "    parent_parents = list(dg.predecessors(parent))\n",
    "    child_parents = list(dg.predecessors(child))\n",
    "    X_cols = list(set(parent_parents + child_parents))\n",
    "\n",
    "    if parent in X_cols:\n",
    "        X_cols.remove(parent)\n",
    "    X = data_df[X_cols]\n",
    "    T = data_df[parent]\n",
    "    Y = data_df[child]\n",
    "\n",
    "    est = LinearDML(\n",
    "        model_y=LinearRegression(),\n",
    "        model_t=LinearRegression(),\n",
    "        # featurizer=PolynomialFeatures(degree=1, include_bias=False),\n",
    "        )\n",
    "    est.fit(Y, T, X=X)\n",
    "    ate = est.ate(X=ref_df[X_cols], T0=T0, T1=T1)\n",
    "\n",
    "    return ate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = os.path.join(\n",
    ")\n",
    "with open(graph_path, \"r\") as fin:\n",
    "    origin_gfile = fin.read().splitlines()\n",
    "\n",
    "collected_df = pd.read_csv(\n",
    ")\n",
    "collected_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "collected_df.dropna(inplace=True)\n",
    "collected_df.fillna(0, inplace=True)\n",
    "collected_df = collected_df.sample(frac=1).reset_index(drop=True)\n",
    "print(f\"Collected data shape: {collected_df.shape}\")\n",
    "print(f\"Collected data columns: {collected_df.columns}\")\n",
    "data_df = collected_df.copy()\n",
    "\n",
    "instruction_cols = [\"long\", \"short\", \"formal\", \"fluent\", \"technical\", \"logical\"]\n",
    "role_cols = [\"student\", \"programmer\", \"competitor\"]\n",
    "scenario_cols = [\"clearer\", \"improve\", \"specify\"]\n",
    "cm_cols = [\n",
    "    \"semgrep\",\n",
    "    \"black\",\n",
    "    \"syntaxError_rate\",\n",
    "    \"sta_codeBleu\",\n",
    "    \"sta_Bleu\",\n",
    "    \"sim_codeBleu\",\n",
    "    \"sim_Bleu\",\n",
    "    \"pass_rate\",\n",
    "    \"error_rate\",\n",
    "    \"timeout_rate\",\n",
    "]\n",
    "\n",
    "meta_cols = []\n",
    "for c in instruction_cols:\n",
    "    meta_cols.append(\"Inst_\" + c)\n",
    "for c in role_cols:\n",
    "    meta_cols.append(\"Role_\" + c)\n",
    "for c in scenario_cols:\n",
    "    meta_cols.append(\"Scen_\" + c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_list = []\n",
    "for edge in origin_gfile:\n",
    "    parent, child = edge.split(' -> ')\n",
    "    trace_list.append((parent, child))\n",
    "\n",
    "dg = nx.DiGraph()\n",
    "dg.add_edges_from(trace_list)\n",
    "\n",
    "# temp_graph = \"digraph {\" + \\\n",
    "#     ' '.join(origin_gfile) + \"}\"\n",
    "sorted_nodes = list(nx.topological_sort(dg))\n",
    "sorted_nodes.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_node = \"\"\n",
    "cm_node = \"\"\n",
    "\n",
    "all_anc = list(nx.ancestors(dg, cm_node))\n",
    "for cm in cm_cols:\n",
    "    if cm in all_anc:\n",
    "        all_anc.remove(cm)\n",
    "\n",
    "if len(all_anc) > 0:\n",
    "    abs_ate = {}\n",
    "    count = 0\n",
    "    for node in tqdm(sorted_nodes):\n",
    "        if node in all_anc:\n",
    "            T0 = 0\n",
    "            T1 = data_df[data_df[meta_node] == 1][cm_node].mean()\n",
    "            ref_df = data_df[data_df[meta_node] == 0]\n",
    "            try:\n",
    "                ate = compute_ate(node, cm_node, data_df, ref_df, dg, T0, T1)\n",
    "            except:\n",
    "                continue\n",
    "            else:\n",
    "                abs_ate[node] = ate\n",
    "                count += 1      \n",
    "\n",
    "    sorted_ate = sorted(abs_ate.items(), key=lambda kv: abs(kv[1]), reverse=True)\n",
    "\n",
    "    for anc, ate in sorted_ate:\n",
    "        print(f\"{anc} -> {cm_node}: {ate}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
