{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all csv in the folder\n",
    "root_path = \"\"\n",
    "ling_origr_df = pd.DataFrame()\n",
    "ling_reph_df = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    # if root.endswith(\"merged\"):\n",
    "    #     continue\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_name = file.split(\".\")[0]\n",
    "            split_name, mark = file_name.split(\"_\")\n",
    "            # if split_name == \"test\":\n",
    "            #     continue\n",
    "            if mark.startswith(\"original\"):\n",
    "                df = pd.read_csv(root + file)\n",
    "                df[\"split_name\"] = split_name\n",
    "                print(f\"Read {file_name} with shape {df.shape}\")\n",
    "                ling_origr_df = pd.concat([ling_origr_df, df])\n",
    "            elif mark.startswith(\"rephrased\"):\n",
    "                df = pd.read_csv(root + file)\n",
    "                df[\"split_name\"] = split_name\n",
    "                print(f\"Read {file_name} with shape {df.shape}\")\n",
    "                ling_reph_df = pd.concat([ling_reph_df, df])\n",
    "            else:\n",
    "                print(f\"Error: file name: {file_name} is not correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_reph_df = ling_reph_df[ling_reph_df[\"re_idx\"] == 0]\n",
    "\n",
    "feat_cols = list(\n",
    "    set(ling_origr_df.columns)\n",
    "    - set([\"p_idx\", \"question_NL\", \"question_example\", \"difficulty\", \"split_name\"])\n",
    ")\n",
    "\n",
    "# merge two dataframes based on the p_idx\n",
    "ling_merged_df = pd.merge(\n",
    "    ling_origr_df,\n",
    "    ling_reph_df,\n",
    "    on=[\"p_idx\", \"split_name\"],\n",
    "    suffixes=(\"_original\", \"_rephrased\"),\n",
    ")\n",
    "\n",
    "# convert Instruction to one-hot encoding\n",
    "# ling_merged_df = pd.get_dummies(ling_merged_df, columns=[\"Instruction\", \"Role\", \"Scenario\"], prefix=[\"Inst\", \"Role\", \"Scen\"])\n",
    "# ling_merged_df = ling_merged_df.drop(columns=[\"Inst_None\", \"Role_None\", \"Scen_None\"])\n",
    "\n",
    "instruction_cols = [\"long\", \"short\", \"formal\", \"fluent\", \"technical\", \"logical\"]\n",
    "role_cols = [\"student\", \"programmer\", \"competitor\"]\n",
    "scenario_cols = [\"clearer\", \"improve\", \"specify\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"neo\"\n",
    "root_path = os.path.join()\n",
    "code_origr_df = pd.DataFrame()\n",
    "code_reph_df = pd.DataFrame()\n",
    "\n",
    "for root, dirs, files in os.walk(root_path):\n",
    "    # if root.endswith(\"merged\"):\n",
    "    #     continue\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_name = file.split(\".\")[0]\n",
    "            split_name, mark, _, _ = file_name.split(\"_\")\n",
    "            # if split_name == \"test\":\n",
    "            #     continue\n",
    "            if mark.startswith(\"original\"):\n",
    "                df = pd.read_csv(os.path.join(root, file))\n",
    "                df[\"split_name\"] = split_name\n",
    "                print(f\"Read {file_name} with shape {df.shape}\")\n",
    "                code_origr_df = pd.concat([code_origr_df, df])\n",
    "            elif mark.startswith(\"rephrased\"):\n",
    "                df = pd.read_csv(os.path.join(root, file))\n",
    "                df[\"split_name\"] = split_name\n",
    "                print(f\"Read {file_name} with shape {df.shape}\")\n",
    "                code_reph_df = pd.concat([code_reph_df, df])\n",
    "            else:\n",
    "                print(f\"Error: file name: {file_name} is not correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_cols = [\n",
    "    \"semgrep\",\n",
    "    \"black\",\n",
    "    \"syntaxError_rate\",\n",
    "    \"sta_codeBleu\",\n",
    "    \"sta_Bleu\",\n",
    "    \"sim_codeBleu\",\n",
    "    \"sim_Bleu\",\n",
    "    \"pass_rate\",\n",
    "    \"error_rate\",\n",
    "    \"timeout_rate\",\n",
    "]\n",
    "\n",
    "code_origr_df = code_origr_df.drop(columns=[\"Instruction\", \"Role\", \"Scenario\", \"Base\"])\n",
    "\n",
    "# merge two dataframes based on the p_idx\n",
    "code_merged_df = pd.merge(\n",
    "    code_origr_df,\n",
    "    code_reph_df,\n",
    "    on=[\"p_idx\", \"split_name\"],\n",
    "    suffixes=(\"_original\", \"_rephrased\"),\n",
    ").dropna()\n",
    "# code_merged_df = pd.get_dummies(code_merged_df, columns=[\"Instruction\", \"Role\", \"Scenario\"], prefix=[\"Inst\", \"Role\", \"Scen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_df = pd.merge(\n",
    "    ling_merged_df,\n",
    "    code_merged_df,\n",
    "    on=[\"p_idx\", \"Instruction\", \"Role\", \"Scenario\", \"split_name\"],\n",
    "    how=\"inner\",\n",
    ").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = fin_df.loc[\n",
    "    (fin_df[\"Instruction\"] == \"None\")\n",
    "    & (fin_df[\"Role\"] == \"None\")\n",
    "    & (fin_df[\"Scenario\"] == \"None\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_dif = pd.DataFrame()\n",
    "cm_dif = pd.DataFrame()\n",
    "cm_orig = pd.DataFrame()\n",
    "\n",
    "for fc in feat_cols:\n",
    "    ling_dif[fc] = fin_df[fc + \"_rephrased\"] - fin_df[fc + \"_original\"]\n",
    "\n",
    "for cm in cm_cols:\n",
    "    cm_dif[cm] = fin_df[cm + \"_rephrased\"] - fin_df[cm + \"_original\"]\n",
    "    cm_orig[cm + \"_orig\"] = fin_df[cm + \"_original\"]\n",
    "\n",
    "causal_df = pd.concat([ling_dif, cm_dif], axis=1)\n",
    "\n",
    "fin_df = pd.get_dummies(fin_df, columns=[\"Instruction\", \"Role\", \"Scenario\"], prefix=[\"Inst\", \"Role\", \"Scen\"])\n",
    "fin_df = fin_df.drop(columns=[\"Inst_None\", \"Role_None\", \"Scen_None\"])\n",
    "\n",
    "meta_cols = []\n",
    "for c in instruction_cols:\n",
    "    meta_cols.append(\"Inst_\" + c)\n",
    "for c in role_cols:\n",
    "    meta_cols.append(\"Role_\" + c)\n",
    "for c in scenario_cols:\n",
    "    meta_cols.append(\"Scen_\" + c)\n",
    "\n",
    "causal_df = pd.concat([fin_df[meta_cols], causal_df], axis=1)\n",
    "causal_df.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat ling_dif and cm_diff\n",
    "all_dif_df = pd.concat([ling_dif, cm_dif, cm_orig], axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
